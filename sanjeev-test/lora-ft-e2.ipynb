{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d233e121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading datasets...\n",
      "Datasets loaded and size-limited.\n",
      "\n",
      "Preprocessing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 400/400 [00:00<00:00, 9469.45 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 6073.86 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 6727.25 examples/s]\n",
      "Map: 100%|██████████| 400/400 [00:00<00:00, 1957.29 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 2087.64 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1821.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n",
      "\n",
      "\n",
      "============================================================\n",
      "RUNNING: LORA → CLASSIFICATION\n",
      "============================================================\n",
      "\n",
      "trainable params: 589,824 || all params: 61,096,448 || trainable%: 0.9654\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 01:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.975500</td>\n",
       "      <td>0.131304</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.860215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.203600</td>\n",
       "      <td>0.110173</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.910891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>0.160721</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.880734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.135500</td>\n",
       "      <td>0.123963</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>0.125405</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.891089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.141117</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.895833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.154865</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.905660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.145613</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.893204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.158835</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.149155</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.901961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix → ./plots/lora_classification_cm.png\n",
      "Model saved → ./models/classification/lora\n",
      "\n",
      "\n",
      "============================================================\n",
      "RUNNING: LORA → SUMMARIZATION\n",
      "============================================================\n",
      "\n",
      "trainable params: 589,824 || all params: 61,096,448 || trainable%: 0.9654\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 03:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.441800</td>\n",
       "      <td>2.049999</td>\n",
       "      <td>0.371073</td>\n",
       "      <td>0.143072</td>\n",
       "      <td>0.309358</td>\n",
       "      <td>0.309053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.297100</td>\n",
       "      <td>2.021712</td>\n",
       "      <td>0.349211</td>\n",
       "      <td>0.133479</td>\n",
       "      <td>0.299011</td>\n",
       "      <td>0.298706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.121500</td>\n",
       "      <td>1.983386</td>\n",
       "      <td>0.355061</td>\n",
       "      <td>0.126501</td>\n",
       "      <td>0.296757</td>\n",
       "      <td>0.295796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.091000</td>\n",
       "      <td>1.967239</td>\n",
       "      <td>0.380557</td>\n",
       "      <td>0.154854</td>\n",
       "      <td>0.326603</td>\n",
       "      <td>0.327599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.957600</td>\n",
       "      <td>1.971286</td>\n",
       "      <td>0.386323</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.322608</td>\n",
       "      <td>0.323891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.052500</td>\n",
       "      <td>1.959328</td>\n",
       "      <td>0.375455</td>\n",
       "      <td>0.143192</td>\n",
       "      <td>0.313796</td>\n",
       "      <td>0.313249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.038400</td>\n",
       "      <td>1.984287</td>\n",
       "      <td>0.389482</td>\n",
       "      <td>0.162127</td>\n",
       "      <td>0.332076</td>\n",
       "      <td>0.332500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.939200</td>\n",
       "      <td>1.960637</td>\n",
       "      <td>0.387699</td>\n",
       "      <td>0.154319</td>\n",
       "      <td>0.328043</td>\n",
       "      <td>0.327881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.912700</td>\n",
       "      <td>1.959867</td>\n",
       "      <td>0.388008</td>\n",
       "      <td>0.149946</td>\n",
       "      <td>0.324681</td>\n",
       "      <td>0.324019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.797500</td>\n",
       "      <td>1.965467</td>\n",
       "      <td>0.381731</td>\n",
       "      <td>0.145084</td>\n",
       "      <td>0.324338</td>\n",
       "      <td>0.325352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample outputs → ./samples/lora_summarization_samples.txt\n",
      "Hallucination report → ./hallucinations/lora_summarization_hallucinations.json (Avg: 0.65)\n",
      "Length plot → ./plots/lora_summarization_length.png\n",
      "Model saved → ./models/summarization/lora\n",
      "\n",
      "\n",
      "============================================================\n",
      "RUNNING: PREFIX → CLASSIFICATION\n",
      "============================================================\n",
      "\n",
      "trainable params: 6,576,640 || all params: 67,083,264 || trainable%: 9.8037\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.157320</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.163229</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.209596</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.216697</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.195600</td>\n",
       "      <td>0.179496</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.167500</td>\n",
       "      <td>0.167158</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.224600</td>\n",
       "      <td>0.166020</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.170829</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.151933</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.140414</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix → ./plots/prefix_classification_cm.png\n",
      "Model saved → ./models/classification/prefix\n",
      "\n",
      "\n",
      "============================================================\n",
      "RUNNING: PREFIX → SUMMARIZATION\n",
      "============================================================\n",
      "\n",
      "trainable params: 6,576,640 || all params: 67,083,264 || trainable%: 9.8037\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 02:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.486100</td>\n",
       "      <td>2.221143</td>\n",
       "      <td>0.211207</td>\n",
       "      <td>0.046997</td>\n",
       "      <td>0.173677</td>\n",
       "      <td>0.173870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.464800</td>\n",
       "      <td>2.133411</td>\n",
       "      <td>0.228172</td>\n",
       "      <td>0.065406</td>\n",
       "      <td>0.193293</td>\n",
       "      <td>0.193588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.111016</td>\n",
       "      <td>0.219609</td>\n",
       "      <td>0.048017</td>\n",
       "      <td>0.180934</td>\n",
       "      <td>0.181091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.310300</td>\n",
       "      <td>2.111962</td>\n",
       "      <td>0.216645</td>\n",
       "      <td>0.055071</td>\n",
       "      <td>0.186757</td>\n",
       "      <td>0.186644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.217000</td>\n",
       "      <td>2.082129</td>\n",
       "      <td>0.240345</td>\n",
       "      <td>0.074518</td>\n",
       "      <td>0.204072</td>\n",
       "      <td>0.203342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.325200</td>\n",
       "      <td>2.076801</td>\n",
       "      <td>0.262380</td>\n",
       "      <td>0.073557</td>\n",
       "      <td>0.217175</td>\n",
       "      <td>0.216068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.301400</td>\n",
       "      <td>2.076730</td>\n",
       "      <td>0.232320</td>\n",
       "      <td>0.071348</td>\n",
       "      <td>0.203068</td>\n",
       "      <td>0.202896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.234100</td>\n",
       "      <td>2.068144</td>\n",
       "      <td>0.226766</td>\n",
       "      <td>0.065467</td>\n",
       "      <td>0.197035</td>\n",
       "      <td>0.197042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.178500</td>\n",
       "      <td>2.059727</td>\n",
       "      <td>0.233931</td>\n",
       "      <td>0.071040</td>\n",
       "      <td>0.197411</td>\n",
       "      <td>0.196457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.132300</td>\n",
       "      <td>2.058427</td>\n",
       "      <td>0.232897</td>\n",
       "      <td>0.070357</td>\n",
       "      <td>0.195948</td>\n",
       "      <td>0.195370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample outputs → ./samples/prefix_summarization_samples.txt\n",
      "Hallucination report → ./hallucinations/prefix_summarization_hallucinations.json (Avg: 0.77)\n",
      "Length plot → ./plots/prefix_summarization_length.png\n",
      "Model saved → ./models/summarization/prefix\n",
      "\n",
      "\n",
      "============================================================\n",
      "RUNNING: PROMPT → CLASSIFICATION\n",
      "============================================================\n",
      "\n",
      "trainable params: 20,480 || all params: 60,527,104 || trainable%: 0.0338\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 01:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>8.512400</td>\n",
       "      <td>8.933566</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>7.918700</td>\n",
       "      <td>7.889293</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>7.076400</td>\n",
       "      <td>6.774876</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6.181000</td>\n",
       "      <td>5.292969</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.421900</td>\n",
       "      <td>4.071288</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.340700</td>\n",
       "      <td>3.338909</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.945700</td>\n",
       "      <td>2.967470</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.435300</td>\n",
       "      <td>2.821554</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.459900</td>\n",
       "      <td>2.740876</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.251900</td>\n",
       "      <td>2.710925</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix → ./plots/prompt_classification_cm.png\n",
      "Model saved → ./models/classification/prompt\n",
      "\n",
      "\n",
      "============================================================\n",
      "RUNNING: PROMPT → SUMMARIZATION\n",
      "============================================================\n",
      "\n",
      "trainable params: 20,480 || all params: 60,527,104 || trainable%: 0.0338\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 22:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.963100</td>\n",
       "      <td>2.808728</td>\n",
       "      <td>0.250587</td>\n",
       "      <td>0.064768</td>\n",
       "      <td>0.213679</td>\n",
       "      <td>0.213019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.071000</td>\n",
       "      <td>2.787029</td>\n",
       "      <td>0.237949</td>\n",
       "      <td>0.060519</td>\n",
       "      <td>0.202999</td>\n",
       "      <td>0.202012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.045300</td>\n",
       "      <td>2.767738</td>\n",
       "      <td>0.240228</td>\n",
       "      <td>0.061699</td>\n",
       "      <td>0.203396</td>\n",
       "      <td>0.202886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.999100</td>\n",
       "      <td>2.752258</td>\n",
       "      <td>0.243741</td>\n",
       "      <td>0.060666</td>\n",
       "      <td>0.203897</td>\n",
       "      <td>0.203329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.950900</td>\n",
       "      <td>2.738896</td>\n",
       "      <td>0.243029</td>\n",
       "      <td>0.059092</td>\n",
       "      <td>0.204157</td>\n",
       "      <td>0.203107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>2.728858</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.202580</td>\n",
       "      <td>0.201716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.045700</td>\n",
       "      <td>2.721349</td>\n",
       "      <td>0.246462</td>\n",
       "      <td>0.058071</td>\n",
       "      <td>0.203892</td>\n",
       "      <td>0.203222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.976700</td>\n",
       "      <td>2.715773</td>\n",
       "      <td>0.240166</td>\n",
       "      <td>0.056487</td>\n",
       "      <td>0.199239</td>\n",
       "      <td>0.198333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.981600</td>\n",
       "      <td>2.712379</td>\n",
       "      <td>0.239254</td>\n",
       "      <td>0.054466</td>\n",
       "      <td>0.198830</td>\n",
       "      <td>0.197900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.884000</td>\n",
       "      <td>2.711605</td>\n",
       "      <td>0.238409</td>\n",
       "      <td>0.054074</td>\n",
       "      <td>0.197660</td>\n",
       "      <td>0.196951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 28c55226-a253-47a8-869a-d6d3bb325ff7)')' thrown while requesting HEAD https://huggingface.co/t5-small/resolve/main/config.json\n",
      "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 28c55226-a253-47a8-869a-d6d3bb325ff7)')' thrown while requesting HEAD https://huggingface.co/t5-small/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample outputs → ./samples/prompt_summarization_samples.txt\n",
      "Hallucination report → ./hallucinations/prompt_summarization_hallucinations.json (Avg: 0.49)\n",
      "Length plot → ./plots/prompt_summarization_length.png\n",
      "Model saved → ./models/summarization/prompt\n",
      "\n",
      "\n",
      "============================================================\n",
      "RUNNING: FULL_FT → CLASSIFICATION\n",
      "============================================================\n",
      "\n",
      "trainable: 60,506,624 || total: 60,506,624 || %: 100.00\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 01:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.325700</td>\n",
       "      <td>0.221276</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.860215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.214400</td>\n",
       "      <td>0.117669</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.893204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.129189</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.868687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.137275</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.151357</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.156720</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.159077</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.110600</td>\n",
       "      <td>0.158053</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>0.158719</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix → ./plots/full_ft_classification_cm.png\n",
      "Model saved → ./models/classification/full_ft\n",
      "\n",
      "\n",
      "============================================================\n",
      "RUNNING: FULL_FT → SUMMARIZATION\n",
      "============================================================\n",
      "\n",
      "trainable: 60,506,624 || total: 60,506,624 || %: 100.00\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/500 01:01 < 03:37, 1.79 it/s, Epoch 1.11/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.636500</td>\n",
       "      <td>2.226545</td>\n",
       "      <td>0.313738</td>\n",
       "      <td>0.095529</td>\n",
       "      <td>0.257166</td>\n",
       "      <td>0.257051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.384700</td>\n",
       "      <td>2.068242</td>\n",
       "      <td>0.347125</td>\n",
       "      <td>0.121778</td>\n",
       "      <td>0.294740</td>\n",
       "      <td>0.295163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "ERROR:__main__:ERROR in full_ft_summarization: MPS backend out of memory (MPS allocated: 4.68 GiB, other allocations: 13.41 GiB, max allowed: 18.13 GiB). Tried to allocate 62.75 MiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "ERROR:__main__:Traceback (most recent call last):\n",
      "  File \"/var/folders/tw/l5tzs72d3dd0wms159v1b2980000gn/T/ipykernel_9505/4286650175.py\", line 409, in <module>\n",
      "    trainer.train()\n",
      "  File \"/Users/sanjeev/personal/IITB-src/dl-project-delta3/.venv/lib/python3.12/site-packages/transformers/trainer.py\", line 2325, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sanjeev/personal/IITB-src/dl-project-delta3/.venv/lib/python3.12/site-packages/transformers/trainer.py\", line 2674, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sanjeev/personal/IITB-src/dl-project-delta3/.venv/lib/python3.12/site-packages/transformers/trainer.py\", line 4071, in training_step\n",
      "    self.accelerator.backward(loss, **kwargs)\n",
      "  File \"/Users/sanjeev/personal/IITB-src/dl-project-delta3/.venv/lib/python3.12/site-packages/accelerate/accelerator.py\", line 2740, in backward\n",
      "    loss.backward(**kwargs)\n",
      "  File \"/Users/sanjeev/personal/IITB-src/dl-project-delta3/.venv/lib/python3.12/site-packages/torch/_tensor.py\", line 625, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/Users/sanjeev/personal/IITB-src/dl-project-delta3/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/Users/sanjeev/personal/IITB-src/dl-project-delta3/.venv/lib/python3.12/site-packages/torch/autograd/graph.py\", line 841, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: MPS backend out of memory (MPS allocated: 4.68 GiB, other allocations: 13.41 GiB, max allowed: 18.13 GiB). Tried to allocate 62.75 MiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL RESULTS & ANALYSIS\n",
      "============================================================\n",
      "Report → FINAL_REPORT.md\n",
      "CSV → peft_results_final.csv\n",
      "\n",
      "============================================================\n",
      "SUCCESS: All experiments completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "PEFT Comparison: LoRA, Prefix, Prompt, Full FT\n",
    "Model: t5-small\n",
    "Tasks: SST-2 (Classification), SAMSum (Summarization)\n",
    "\n",
    "FIXED:\n",
    "- IndexError in save_sample_outputs → use safe indexing\n",
    "- All prior fixes included\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import spacy\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    PrefixTuningConfig,\n",
    "    PromptTuningConfig,\n",
    "    TaskType,\n",
    "    PeftModel\n",
    ")\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ========================================\n",
    "# CONFIGURATION\n",
    "# ========================================\n",
    "MODEL_NAME = \"t5-small\"\n",
    "SUMMARIZATION_DATASET = \"knkarthick/samsum\"\n",
    "BENCHAMARK_GLUE = \"glue\"\n",
    "GLUE_DATASET_TASK_SC = \"sst2\"\n",
    "DATASET_SIZE = 400  # or 'full'\n",
    "RUN_ABLATIONS = False\n",
    "RANDOM_SEED = 42\n",
    "NUM_VIRTUAL_TOKENS = 20\n",
    "MAX_POS = 512\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() \n",
    "    else \"mps\" if torch.backends.mps.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load spaCy\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# ========================================\n",
    "# UTILITIES\n",
    "# ========================================\n",
    "def limit_dataset_size(dataset, size):\n",
    "    if size == 'full':\n",
    "        return dataset\n",
    "    return dataset.select(range(min(size, len(dataset))))\n",
    "\n",
    "def setup_tokenizer(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    return tokenizer\n",
    "\n",
    "def safe_cleanup():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    elif device.type == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "# ========================================\n",
    "# DATA LOADING & PREPROCESSING\n",
    "# ========================================\n",
    "print(\"Loading datasets...\")\n",
    "classification_dataset = load_dataset(BENCHAMARK_GLUE, GLUE_DATASET_TASK_SC)\n",
    "summarization_dataset = load_dataset(SUMMARIZATION_DATASET)\n",
    "\n",
    "tokenizer = setup_tokenizer(MODEL_NAME)\n",
    "\n",
    "# Limit size BEFORE preprocessing\n",
    "if DATASET_SIZE != 'full':\n",
    "    for split in ['train', 'validation', 'test']:\n",
    "        size = DATASET_SIZE if split == 'train' else DATASET_SIZE // 4\n",
    "        if split in classification_dataset:\n",
    "            classification_dataset[split] = limit_dataset_size(classification_dataset[split], size)\n",
    "        if split in summarization_dataset:\n",
    "            summarization_dataset[split] = limit_dataset_size(summarization_dataset[split], size)\n",
    "\n",
    "print(\"Datasets loaded and size-limited.\\n\")\n",
    "\n",
    "# Preprocessing\n",
    "print(\"Preprocessing datasets...\")\n",
    "\n",
    "def preprocess_classification(examples):\n",
    "    inputs = [f\"sentiment: {s}\" for s in examples[\"sentence\"]]\n",
    "    labels = [\"positive\" if l == 1 else \"negative\" for l in examples[\"label\"]]\n",
    "    model_inputs = tokenizer(inputs, truncation=True, max_length=MAX_POS)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        label_enc = tokenizer(labels, truncation=True, max_length=8)\n",
    "    model_inputs[\"labels\"] = label_enc[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_classification = classification_dataset.map(\n",
    "    preprocess_classification,\n",
    "    batched=True,\n",
    "    remove_columns=[\"sentence\", \"label\", \"idx\"]\n",
    ")\n",
    "\n",
    "def preprocess_summarization(examples):\n",
    "    inputs = [f\"summarize: {d}\" for d in examples[\"dialogue\"]]\n",
    "    model_inputs = tokenizer(inputs, truncation=True, max_length=MAX_POS)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], truncation=True, max_length=128)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_summarization = summarization_dataset.map(\n",
    "    preprocess_summarization,\n",
    "    batched=True,\n",
    "    remove_columns=[\"dialogue\", \"summary\", \"id\"]\n",
    ")\n",
    "\n",
    "print(\"Preprocessing complete.\\n\")\n",
    "\n",
    "# ========================================\n",
    "# METRICS (FIXED: safe_decode)\n",
    "# ========================================\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def safe_decode(token_ids, tokenizer):\n",
    "    \"\"\"Filter out invalid token IDs before decoding\"\"\"\n",
    "    if token_ids is None:\n",
    "        return []\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    filtered = []\n",
    "    for seq in token_ids:\n",
    "        seq = [t for t in seq if 0 <= t < vocab_size]\n",
    "        filtered.append(seq)\n",
    "    return tokenizer.batch_decode(filtered, skip_special_tokens=True)\n",
    "\n",
    "def compute_classification_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    decoded_preds = safe_decode(preds, tokenizer)\n",
    "    decoded_labels = safe_decode(labels, tokenizer)\n",
    "    y_pred = [1 if p.strip() == \"positive\" else 0 for p in decoded_preds]\n",
    "    y_true = [1 if l.strip() == \"positive\" else 0 for l in decoded_labels]\n",
    "    acc = accuracy_metric.compute(predictions=y_pred, references=y_true)\n",
    "    f1 = f1_metric.compute(predictions=y_pred, references=y_true)\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1[\"f1\"]}\n",
    "\n",
    "def compute_summarization_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    decoded_preds = safe_decode(preds, tokenizer)\n",
    "    decoded_labels = safe_decode(labels, tokenizer)\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return {\n",
    "        \"rouge1\": result[\"rouge1\"],\n",
    "        \"rouge2\": result[\"rouge2\"],\n",
    "        \"rougeL\": result[\"rougeL\"],\n",
    "        \"rougeLsum\": result[\"rougeLsum\"]\n",
    "    }\n",
    "\n",
    "# ========================================\n",
    "# TRAINING ARGS\n",
    "# ========================================\n",
    "def get_training_args(method_name, task_name):\n",
    "    is_peft = method_name in [\"lora\", \"prefix\", \"prompt\"] or \"_ablated_\" in method_name\n",
    "    lr = 1e-3 if is_peft else 5e-5\n",
    "    \n",
    "    if DATASET_SIZE == 'full':\n",
    "        epochs, batch, eval_steps = 3, 8, 500\n",
    "    elif DATASET_SIZE <= 500:\n",
    "        epochs, batch, eval_steps = 5, 4, 50\n",
    "    else:\n",
    "        epochs, batch, eval_steps = 3, 8, 100\n",
    "\n",
    "    use_bf16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "    use_fp16 = False\n",
    "    load_best = method_name == \"full_ft\" or \"lora\" in method_name\n",
    "    \n",
    "    return Seq2SeqTrainingArguments(\n",
    "        output_dir=f\"./results/{task_name}/{method_name}\",\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch,\n",
    "        per_device_eval_batch_size=batch * 2,\n",
    "        learning_rate=lr,\n",
    "        warmup_steps=min(100, DATASET_SIZE // 10) if DATASET_SIZE != 'full' else 500,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"steps\" if DATASET_SIZE != 'full' else \"epoch\",\n",
    "        eval_steps=eval_steps if DATASET_SIZE != 'full' else None,\n",
    "        save_strategy=\"steps\" if DATASET_SIZE != 'full' else \"epoch\",\n",
    "        save_steps=eval_steps if DATASET_SIZE != 'full' else None,\n",
    "        load_best_model_at_end=load_best,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        save_total_limit=2,\n",
    "        logging_steps=20 if DATASET_SIZE != 'full' else 100,\n",
    "        bf16=use_bf16,\n",
    "        fp16=use_fp16,\n",
    "        dataloader_num_workers=0,\n",
    "        dataloader_drop_last=True,\n",
    "        report_to=\"none\",\n",
    "        predict_with_generate=True,\n",
    "        max_grad_norm=1.0,\n",
    "        gradient_checkpointing=False,\n",
    "    )\n",
    "\n",
    "# ========================================\n",
    "# PLOTTING & ANALYSIS\n",
    "# ========================================\n",
    "def plot_learning_curves(log_history, exp_name, task_name, save_dir=\"./plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    steps = [log['step'] for log in log_history if 'step' in log]\n",
    "    train_losses = [log['train_loss'] for log in log_history if 'train_loss' in log]\n",
    "    eval_losses = [log['eval_loss'] for log in log_history if 'eval_loss' in log]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    axes[0].plot(steps[:len(train_losses)], train_losses, label='Train Loss', marker='o')\n",
    "    if eval_losses:\n",
    "        axes[0].plot(steps[:len(eval_losses)], eval_losses, label='Eval Loss', marker='s')\n",
    "    axes[0].set_xlabel('Step')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title(f'{exp_name} - Loss')\n",
    "    axes[0].legend()\n",
    "\n",
    "    metric_key = 'eval_accuracy' if task_name == \"classification\" else 'eval_rougeL'\n",
    "    metric_vals = [log.get(metric_key) for log in log_history if metric_key in log]\n",
    "    if metric_vals:\n",
    "        axes[1].plot(steps[:len(metric_vals)], metric_vals, label=metric_key.split('_')[1].upper(), color='green', marker='o')\n",
    "        axes[1].set_ylabel(metric_key.split('_')[1].upper())\n",
    "    axes[1].set_xlabel('Step')\n",
    "    axes[1].set_title(f'{exp_name} - Metric')\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    path = f\"{save_dir}/{exp_name}_curves.png\"\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "    print(f\"Learning curves → {path}\")\n",
    "    return path\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, exp_name, save_dir=\"./plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix - {exp_name}')\n",
    "    path = f\"{save_dir}/{exp_name}_cm.png\"\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix → {path}\")\n",
    "    return path\n",
    "\n",
    "def save_sample_outputs(trainer, dataset, exp_name, n=5, save_dir=\"./samples\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    samples = dataset[\"test\"].select(range(min(n, len(dataset[\"test\"]))))\n",
    "    \n",
    "    preds = trainer.predict(samples)\n",
    "    decoded_preds = safe_decode(preds.predictions, tokenizer)\n",
    "    decoded_labels = safe_decode(preds.label_ids, tokenizer)\n",
    "    \n",
    "    input_ids = samples[\"input_ids\"]\n",
    "    inputs = [tokenizer.decode(ids, skip_special_tokens=True).replace(\"summarize: \", \"\") for ids in input_ids]\n",
    "\n",
    "    # SAFE INDEXING\n",
    "    num_samples = min(len(inputs), len(decoded_preds), len(decoded_labels))\n",
    "    \n",
    "    path = f\"{save_dir}/{exp_name}_samples.txt\"\n",
    "    with open(path, \"w\") as f:\n",
    "        for i in range(num_samples):\n",
    "            f.write(f\"INPUT:\\n{inputs[i]}\\n\\n\")\n",
    "            f.write(f\"PREDICTED:\\n{decoded_preds[i]}\\n\\n\")\n",
    "            f.write(f\"TRUE:\\n{decoded_labels[i]}\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\")\n",
    "    print(f\"Sample outputs → {path}\")\n",
    "    return path\n",
    "\n",
    "def detect_hallucinations(preds, refs):\n",
    "    pred_ents = []\n",
    "    ref_ents = []\n",
    "    for p, r in zip(preds, refs):\n",
    "        pred_doc = nlp(p)\n",
    "        ref_doc = nlp(r)\n",
    "        pred_ents.append({ent.text.lower() for ent in pred_doc.ents})\n",
    "        ref_ents.append({ent.text.lower() for ent in ref_doc.ents})\n",
    "    \n",
    "    hallucinations = []\n",
    "    for p_set, r_set in zip(pred_ents, ref_ents):\n",
    "        extra = p_set - r_set\n",
    "        hallucinations.append(len(extra))\n",
    "    return hallucinations\n",
    "\n",
    "def plot_length_analysis(pred_lens, true_lens, exp_name, save_dir=\"./plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    df = pd.DataFrame({\"Predicted Length\": pred_lens, \"True Length\": true_lens})\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(df, kde=True, bins=20, alpha=0.7)\n",
    "    plt.title(f'Summary Length Distribution - {exp_name}')\n",
    "    plt.xlabel('Length (tokens)')\n",
    "    plt.legend(['Predicted', 'True'])\n",
    "    \n",
    "    path = f\"{save_dir}/{exp_name}_length.png\"\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "    print(f\"Length plot → {path}\")\n",
    "    return path\n",
    "\n",
    "# ========================================\n",
    "# MAIN LOOP\n",
    "# ========================================\n",
    "base_methods = [\"lora\", \"prefix\", \"prompt\", \"full_ft\"]\n",
    "ablation_methods = [\"lora_ablated_alpha0\", \"prefix_ablated_no_proj\", \"prompt_ablated_short\"]\n",
    "methods_to_run = base_methods + (ablation_methods if RUN_ABLATIONS else [])\n",
    "\n",
    "tasks = {\n",
    "    \"classification\": (tokenized_classification, compute_classification_metrics),\n",
    "    \"summarization\": (tokenized_summarization, compute_summarization_metrics)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "os.makedirs(\"./results\", exist_ok=True)\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "os.makedirs(\"./plots\", exist_ok=True)\n",
    "os.makedirs(\"./samples\", exist_ok=True)\n",
    "os.makedirs(\"./hallucinations\", exist_ok=True)\n",
    "\n",
    "for method_name in methods_to_run:\n",
    "    for task_name, (dataset, compute_metrics) in tasks.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"RUNNING: {method_name.upper()} → {task_name.upper()}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "        try:\n",
    "            config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "            use_bf16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "            model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "                MODEL_NAME,\n",
    "                config=config,\n",
    "                dtype=torch.bfloat16 if use_bf16 else torch.float32\n",
    "            ).to(device)\n",
    "\n",
    "            if method_name != \"full_ft\":\n",
    "                d_model = model.config.d_model\n",
    "                num_heads = model.config.num_heads\n",
    "                total_layers = model.config.num_layers + model.config.num_decoder_layers\n",
    "                peft_configs = {\n",
    "                    \"lora\": LoraConfig(r=16, lora_alpha=32, target_modules=[\"q\", \"v\"], lora_dropout=0.05, bias=\"none\", task_type=TaskType.SEQ_2_SEQ_LM),\n",
    "                    \"lora_ablated_alpha0\": LoraConfig(r=16, lora_alpha=0, target_modules=[\"q\", \"v\"], lora_dropout=0.05, bias=\"none\", task_type=TaskType.SEQ_2_SEQ_LM),\n",
    "                    \"prefix\": PrefixTuningConfig(task_type=TaskType.SEQ_2_SEQ_LM, num_virtual_tokens=NUM_VIRTUAL_TOKENS, token_dim=d_model, num_attention_heads=num_heads, num_layers=total_layers, num_transformer_submodules=2, encoder_hidden_size=d_model, prefix_projection=True),\n",
    "                    \"prefix_ablated_no_proj\": PrefixTuningConfig(task_type=TaskType.SEQ_2_SEQ_LM, num_virtual_tokens=NUM_VIRTUAL_TOKENS, token_dim=d_model, num_attention_heads=num_heads, num_layers=total_layers, num_transformer_submodules=2, encoder_hidden_size=d_model, prefix_projection=False),\n",
    "                    \"prompt\": PromptTuningConfig(num_virtual_tokens=NUM_VIRTUAL_TOKENS, task_type=TaskType.SEQ_2_SEQ_LM),\n",
    "                    \"prompt_ablated_short\": PromptTuningConfig(num_virtual_tokens=NUM_VIRTUAL_TOKENS // 2, task_type=TaskType.SEQ_2_SEQ_LM),\n",
    "                }\n",
    "                model = get_peft_model(model, peft_configs[method_name])\n",
    "                model.print_trainable_parameters()\n",
    "                model.train()\n",
    "                model.config.use_cache = False\n",
    "            else:\n",
    "                trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "                total = sum(p.numel() for p in model.parameters())\n",
    "                print(f\"trainable: {trainable:,} || total: {total:,} || %: 100.00\")\n",
    "\n",
    "            args = get_training_args(method_name, task_name)\n",
    "            collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
    "            trainer = Seq2SeqTrainer(\n",
    "                model=model, args=args, train_dataset=dataset[\"train\"],\n",
    "                eval_dataset=dataset[\"validation\"], data_collator=collator,\n",
    "                compute_metrics=compute_metrics, tokenizer=tokenizer\n",
    "            )\n",
    "\n",
    "            print(\"Training...\")\n",
    "            trainer.train()\n",
    "\n",
    "            print(\"Evaluating...\")\n",
    "            test_ds = dataset.get(\"test\", dataset[\"validation\"])\n",
    "            test_metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "            # === ANALYSIS ===\n",
    "            exp_name = f\"{method_name}_{task_name}\"\n",
    "            preds = trainer.predict(test_ds)\n",
    "            decoded_preds = safe_decode(preds.predictions, tokenizer)\n",
    "            decoded_labels = safe_decode(preds.label_ids, tokenizer)\n",
    "\n",
    "            # 1. Confusion Matrix\n",
    "            cm_path = None\n",
    "            if task_name == \"classification\":\n",
    "                y_pred = [1 if p.strip() == \"positive\" else 0 for p in decoded_preds]\n",
    "                y_true = [1 if l.strip() == \"positive\" else 0 for l in decoded_labels]\n",
    "                cm_path = plot_confusion_matrix(y_true, y_pred, exp_name)\n",
    "\n",
    "            # 2. Sample Outputs\n",
    "            sample_path = None\n",
    "            if task_name == \"summarization\":\n",
    "                sample_path = save_sample_outputs(trainer, dataset, exp_name, n=5)\n",
    "\n",
    "            # 3. ROUGE\n",
    "            rouge1 = test_metrics.get(\"eval_rouge1\", 0)\n",
    "            rouge2 = test_metrics.get(\"eval_rouge2\", 0)\n",
    "            rougeL = test_metrics.get(\"eval_rougeL\", 0)\n",
    "\n",
    "            # 4. Hallucination\n",
    "            hall_path = None\n",
    "            if task_name == \"summarization\":\n",
    "                halls = detect_hallucinations(decoded_preds, decoded_labels)\n",
    "                avg_hall = np.mean(halls)\n",
    "                with open(f\"./hallucinations/{exp_name}_hallucinations.json\", \"w\") as f:\n",
    "                    json.dump({\"avg_hallucinated_entities\": avg_hall, \"per_sample\": halls}, f, indent=2)\n",
    "                hall_path = f\"./hallucinations/{exp_name}_hallucinations.json\"\n",
    "                print(f\"Hallucination report → {hall_path} (Avg: {avg_hall:.2f})\")\n",
    "\n",
    "            # 5. Length\n",
    "            len_path = None\n",
    "            if task_name == \"summarization\":\n",
    "                pred_lens = [len(tokenizer.encode(p, add_special_tokens=False)) for p in decoded_preds]\n",
    "                true_lens = [len(tokenizer.encode(t, add_special_tokens=False)) for t in decoded_labels]\n",
    "                len_path = plot_length_analysis(pred_lens, true_lens, exp_name)\n",
    "\n",
    "            # Save results\n",
    "            trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            total = sum(p.numel() for p in model.parameters())\n",
    "            results[exp_name] = {\n",
    "                \"test_metrics\": test_metrics,\n",
    "                \"trainable_params\": trainable,\n",
    "                \"total_params\": total,\n",
    "                \"log_history\": trainer.state.log_history,\n",
    "                \"cm_plot\": cm_path,\n",
    "                \"sample_path\": sample_path,\n",
    "                \"hallucination_path\": hall_path,\n",
    "                \"length_plot\": len_path\n",
    "            }\n",
    "\n",
    "            save_path = f\"./models/{task_name}/{method_name}\"\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            trainer.save_model(save_path)\n",
    "            print(f\"Model saved → {save_path}\\n\")\n",
    "\n",
    "            del model, trainer\n",
    "            safe_cleanup()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ERROR in {method_name}_{task_name}: {e}\")\n",
    "            import traceback\n",
    "            logger.error(traceback.format_exc())\n",
    "            safe_cleanup()\n",
    "\n",
    "# ========================================\n",
    "# FINAL REPORT\n",
    "# ========================================\n",
    "if results:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL RESULTS & ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    rows = []\n",
    "    for exp, data in results.items():\n",
    "        m, t = exp.split(\"_\", 1)\n",
    "        row = {\"Method\": m.upper(), \"Task\": t.capitalize(), \"Trainable %\": round(100 * data[\"trainable_params\"] / data[\"total_params\"], 2)}\n",
    "        row.update({k.replace(\"eval_\", \"\"): v for k, v in data[\"test_metrics\"].items() if \"eval_\" in k})\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(\"peft_results_final.csv\", index=False)\n",
    "\n",
    "    with open(\"FINAL_REPORT.md\", \"w\") as f:\n",
    "        f.write(\"# PEFT Comparison - Final Report\\n\\n\")\n",
    "        f.write(f\"**Model**: {MODEL_NAME} | **Size**: {DATASET_SIZE}\\n\\n\")\n",
    "        f.write(\"## Metrics Table\\n\\n\")\n",
    "        f.write(df.to_markdown(index=False))\n",
    "        f.write(\"\\n\\n## Outputs\\n\")\n",
    "        for exp, data in results.items():\n",
    "            f.write(f\"\\n### {exp.upper()}\\n\")\n",
    "            if data[\"cm_plot\"]: f.write(f\"- [Confusion Matrix]({data['cm_plot']})\\n\")\n",
    "            if data[\"sample_path\"]: f.write(f\"- [Sample Outputs]({data['sample_path']})\\n\")\n",
    "            if data[\"hallucination_path\"]: f.write(f\"- [Hallucination Report]({data['hallucination_path']})\\n\")\n",
    "            if data[\"length_plot\"]: f.write(f\"- [Length Analysis]({data['length_plot']})\\n\")\n",
    "\n",
    "    print(\"Report → FINAL_REPORT.md\")\n",
    "    print(\"CSV → peft_results_final.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUCCESS: All experiments completed!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
